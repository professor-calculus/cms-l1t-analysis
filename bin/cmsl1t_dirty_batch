#!/usr/bin/env python

from __future__ import print_function
import click
import click_log
import yaml
import os
from cmsl1t.config import ConfigParser, get_unique_out_dir
import htcondor
import sys
import math
from textwrap import dedent
import logging
import subprocess
logger = logging.getLogger(__name__)
click_log.basic_config(logger)


class cmsl1t_batch_job_htcondor(object):
    run_script_name = "run_script.sh"

    def __init__(self, batch_directory, debug):
        self.debug = debug
        setup_script = os.path.join(os.environ["PROJECT_ROOT"], "bin", "env.sh")

        run_script_contents = dedent("""\
        #! /bin/bash
        source {setup_script}
        cmsl1t $@
        """).format(setup_script=setup_script)

        self.run_script = os.path.realpath(os.path.join(batch_directory, self.run_script_name))
        with open(self.run_script, "w") as run_script:
            run_script.write(run_script_contents)
        os.chmod(self.run_script, 0777)

    def submit(self, config_files):
        logger.info("Will submit %d jobs" % len(config_files))
        schedd = htcondor.Schedd()
        results = []
        for cfg in config_files:
            with schedd.transaction() as txn:
                cfg = os.path.realpath(cfg)
                job_cfg = dict(executable=self.run_script_name,
                               arguments="-c {}".format(cfg),
                               )
                sub = htcondor.Submit(job_cfg)
                out = sub.queue(txn)
                results.append(out)
        logger.info(dedent("""\
        Jobs should be running on htcondor now.  To monitor their progress use:

            condor_q $USER """))

        return results


class cmsl1t_batch_job_bsub(object):
    run_script_name = "run_script.sh"

    def __init__(self, batch_directory, debug):
        self.batch_directory = batch_directory
        self.debug = debug
        setup_script = os.path.join(os.environ["PROJECT_ROOT"], "bin", "env.sh")

        run_script_contents = dedent("""\
        #! /bin/bash
        pushd {project_root}
        source {setup_script}
        popd
        cmsl1t -c "$1"
        """).format(project_root=os.environ["PROJECT_ROOT"], setup_script=setup_script)

        self.run_script = os.path.realpath(os.path.join(batch_directory, self.run_script_name))
        with open(self.run_script, "w") as run_script:
            run_script.write(run_script_contents)
        os.chmod(self.run_script, 0777)

    def submit(self, config_files):
        n_cfgs = str(len(config_files))
        logger.info("Will submit %s jobs using bsub" % n_cfgs)

        job_group = "/CMS-L1T--"
        directory_name = os.path.basename(os.path.dirname(self.batch_directory))
        job_group += directory_name.replace("/", "--")

        results = []
        for i, cfg in enumerate(config_files):
            logger.info("submitting: " + cfg)
            results.append(self._submit_one(cfg, job_group))

        logger.info("    Check job status using:\n\n         bjobs -g {group}".format(group=job_group))
        return results

    def _submit_one(self, config, group=None):
        # Prepare the args
        args = ["bsub", "-q", "1nh"]
        if group:
            args += ["-g", group]
        if not self.debug:
            args += ["-eo", os.devnull, "-oo", os.devnull]
        command = ' '.join([self.run_script, config])
        args += [command]

        try:
            subprocess.check_output(args)
        except subprocess.CalledProcessError as e:
            msg = dedent("""\
                    Error submitting to bsub.
                    Output was:
                       {e.output}

                    Return code was:
                       {e.returncode}""")
            logger.error(msg.format(e=e))
            return False
        return True


def prepare_input_file_groups(input_ntuples, files_per_job):
    file_lists = []
    current_list = []
    for infile in input_ntuples:
        if not infile.startswith("root:"):
            infile = os.path.realpath(infile)
        current_list.append(infile)

        # Is the current list full?
        if len(current_list) >= files_per_job:
            file_lists.append(current_list)
            current_list = []

    # Even if the last list had fewer files than needed, make sure to use this too
    if current_list:
        file_lists.append(current_list)

    return file_lists


@click.command()
@click.option('-c', '--config_file', help='YAML style config file', type=click.File(), required=True)
@click.option('-f', '--files-per-job', help='Give each job this many files', type=int, default=1)
@click.option('--debug/--no-debug', help='Debug mode for the job submission', default=False)
@click.option('--batch', default="bsub", type=click.Choice(["bsub", "htcondor"]),
              help='Select the job submission system to use')
@click_log.simple_verbosity_option(logger)
def run(config_file, debug, batch, files_per_job):
    # Read the config file
    config = ConfigParser()
    config.read(config_file)

    # Get the list of input files
    input_ntuples = config.get('input', 'files')
    input_ntuples = prepare_input_file_groups(input_ntuples, files_per_job)

    # Get the output directory
    output_directory = config.get('output', 'folder')
    batch_dir = os.path.join(output_directory, "batch")
    batch_dir = get_unique_out_dir(batch_dir)
    batch_config_dir = os.path.join(batch_dir, "_configs")
    logger.info("Batch config files will be placed under: " + batch_config_dir)
    os.makedirs(batch_config_dir)

    # Sort out a name for the batch config files
    n_jobs = len(input_ntuples)
    n_jobs_pad_width = int(math.log10(n_jobs)) + 1
    batch_filename = os.path.basename(config_file.name)
    batch_filename = list(os.path.splitext(batch_filename))
    batch_filename.insert(1, "_{index}")
    batch_filename = "".join(batch_filename)
    batch_filename = os.path.join(batch_config_dir, batch_filename)

    out_dir = "job_{index}"
    out_dir = os.path.join(batch_dir, out_dir)

    padding = "{{:0{}}}".format(n_jobs_pad_width)

    # Prepare input jobs
    job_configs = []
    for i, in_files in enumerate(input_ntuples):
        padded_index = padding.format(i)

        # Reset the input file list
        config.config['input']['files'] = in_files

        # Reset the output directory
        config.config['output']['folder'] = out_dir.format(index=padded_index)

        # Dump the config file
        batch_file = batch_filename.format(index=padded_index)
        config.dump(batch_file)

        job_configs.append(batch_file)

    # Now actually submit the jobs
    if batch == "bsub":
        submitter = cmsl1t_batch_job_bsub(batch_dir, debug)
    elif batch == "htcondor":
        submitter = cmsl1t_batch_job_htcondor(batch_dir, debug)
    result = submitter.submit(job_configs)

    if not all(result):
        logger.error("Error: submitting jobs failed...")
        return False

    # Finally dump the commands needed to run the next steps to screen:
    next_steps = """
    when all jobs are done, you can combine all results together with:

        cmsl1t -c {cfg} -r --hist-files '{out_dir}/*.root'

    ie. use the same config file given here, but reload hists from the intermediate root files.
    """

    logger.info(next_steps.format(cfg=config_file.name,
                                  out_dir=out_dir.format(index="*")))

    return True


if __name__ == '__main__':
    run()
